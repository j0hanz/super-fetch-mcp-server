import type {
  BatchUrlResult,
  FetchUrlsInput,
  SingleUrlResult,
} from '../../config/types.js';

import * as cache from '../../services/cache.js';
import { extractContent } from '../../services/extractor.js';
import { fetchUrlWithRetry } from '../../services/fetcher.js';
import { logDebug, logError, logWarn } from '../../services/logger.js';
import { parseHtml } from '../../services/parser.js';

import { runWithConcurrency } from '../../utils/concurrency.js';
import { createToolErrorResponse } from '../../utils/tool-error-handler.js';
import { validateAndNormalizeUrl } from '../../utils/url-validator.js';
import {
  buildMetadata,
  shouldUseArticle,
  truncateContent,
} from '../utils/common.js';
import { createBatchResponse } from '../utils/response-builder.js';

import { toJsonl } from '../../transformers/jsonl.transformer.js';
import { htmlToMarkdown } from '../../transformers/markdown.transformer.js';

export const FETCH_URLS_TOOL_NAME = 'fetch-urls';
export const FETCH_URLS_TOOL_DESCRIPTION =
  'Fetches multiple URLs in parallel and converts them to AI-readable format (JSONL or Markdown). Supports concurrency control and continues on individual failures.';

const MAX_URLS = 10;
const DEFAULT_CONCURRENCY = 3;

interface ProcessOptions {
  extractMainContent: boolean;
  includeMetadata: boolean;
  maxContentLength?: number | undefined;
  format: 'jsonl' | 'markdown';
}

async function processSingleUrl(
  url: string,
  options: ProcessOptions
): Promise<SingleUrlResult> {
  try {
    const normalizedUrl = validateAndNormalizeUrl(url);
    const cacheNamespace = options.format === 'markdown' ? 'markdown' : 'url';
    const cacheKey = cache.createCacheKey(cacheNamespace, normalizedUrl);

    if (cacheKey) {
      const cached = cache.get(cacheKey);
      if (cached) {
        logDebug('Batch cache hit', { url: normalizedUrl });
        return {
          url: normalizedUrl,
          success: true,
          content: cached.content,
          cached: true,
        };
      }
    }

    const fetchResult = await fetchUrlWithRetry(normalizedUrl);

    // Only invoke JSDOM when extractMainContent is true (lazy loading optimization)
    const { article, metadata: extractedMeta } = extractContent(
      fetchResult.html,
      normalizedUrl,
      {
        extractArticle: options.extractMainContent,
      }
    );
    const useArticle = shouldUseArticle(options.extractMainContent, article);
    const metadata = buildMetadata(
      normalizedUrl,
      article,
      extractedMeta,
      useArticle,
      options.includeMetadata
    );
    const sourceHtml = useArticle ? article.content : fetchResult.html;
    const title = useArticle ? article.title : extractedMeta.title;

    let content: string;
    let contentBlocks: number | undefined;

    if (options.format === 'markdown') {
      content = htmlToMarkdown(sourceHtml, metadata);
    } else {
      const blocks = parseHtml(sourceHtml);
      contentBlocks = blocks.length;
      content = toJsonl(blocks, metadata);
    }

    const { content: truncatedContent } = truncateContent(
      content,
      options.maxContentLength
    );
    content = truncatedContent;
    if (cacheKey) cache.set(cacheKey, content);

    return {
      url: normalizedUrl,
      success: true,
      title,
      content,
      contentBlocks,
      cached: false,
    };
  } catch (error) {
    const errorMessage =
      error instanceof Error ? error.message : 'Unknown error';
    let errorCode = 'FETCH_ERROR';
    if (error && typeof error === 'object' && 'code' in error) {
      errorCode = String((error as Record<string, unknown>).code);
    }

    logWarn('Batch URL processing failed', { url, error: errorMessage });
    return {
      url,
      success: false,
      cached: false,
      error: errorMessage,
      errorCode,
    };
  }
}

export async function fetchUrlsToolHandler(input: FetchUrlsInput) {
  try {
    // Validate input - urls array is guaranteed by Zod schema but check for empty
    if (input.urls.length === 0) {
      return createToolErrorResponse(
        'At least one URL is required',
        '',
        'VALIDATION_ERROR'
      );
    }

    // Enforce max URLs limit
    if (input.urls.length > MAX_URLS) {
      return createToolErrorResponse(
        `Maximum ${MAX_URLS} URLs allowed per batch`,
        '',
        'VALIDATION_ERROR'
      );
    }

    // Filter out empty URLs
    const validUrls = input.urls.filter(
      (url) => typeof url === 'string' && url.trim().length > 0
    );

    if (validUrls.length === 0) {
      return createToolErrorResponse(
        'No valid URLs provided',
        '',
        'VALIDATION_ERROR'
      );
    }

    const concurrency = Math.min(
      Math.max(1, input.concurrency ?? DEFAULT_CONCURRENCY),
      5
    );
    const continueOnError = input.continueOnError ?? true;
    const format = input.format ?? 'jsonl';

    logDebug('Starting batch URL fetch', {
      urlCount: validUrls.length,
      concurrency,
      format,
    });

    // Create tasks for each URL
    const tasks = validUrls.map(
      (url) => async () =>
        processSingleUrl(url, {
          extractMainContent: input.extractMainContent ?? true,
          includeMetadata: input.includeMetadata ?? true,
          maxContentLength: input.maxContentLength,
          format,
        })
    );

    // Execute with concurrency control
    const settledResults = await runWithConcurrency(concurrency, tasks);

    // Process results
    const results: BatchUrlResult[] = settledResults.map((result, index) => {
      if (result.status === 'fulfilled') {
        return result.value;
      } else {
        // Promise rejection (shouldn't happen as processSingleUrl catches errors)
        const reason: unknown = result.reason;
        const errorMessage =
          reason instanceof Error ? reason.message : String(reason);
        return {
          url: validUrls[index] ?? 'unknown',
          success: false as const,
          cached: false as const,
          error: errorMessage,
          errorCode: 'PROMISE_REJECTED',
        };
      }
    });

    // Check if we should fail fast on errors
    if (!continueOnError) {
      const firstError = results.find((r) => !r.success);
      if (firstError) {
        return createToolErrorResponse(
          `Batch failed: ${firstError.error}`,
          firstError.url,
          firstError.errorCode ?? 'BATCH_ERROR'
        );
      }
    }

    return createBatchResponse(results);
  } catch (error) {
    logError(
      'fetch-urls tool error',
      error instanceof Error ? error : undefined
    );

    return createToolErrorResponse(
      error instanceof Error ? error.message : 'Failed to fetch URLs',
      '',
      'BATCH_ERROR'
    );
  }
}
